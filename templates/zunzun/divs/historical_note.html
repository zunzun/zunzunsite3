<div ID="historicalNoteDiv" align='center' name="hideable_div" style="display:block;">
<B><FONT SIZE="+1">Historical Note</FONT></B><BR><BR>
<TABLE ALIGN='center'><tr><td align='left'>
Prior to the invention of electronic calculation, only manual methods were available,<br>
of course - meaning that creating mathematical models from experimental data was<br>
done by hand.  Even Napier's invention of logarithms did not help much in reducing<br>
the tediousness of this task.  Linear regression techniques worked, but how to then<br>
compare models? - and so the F-statistic was created for the purpose of model<br>
selection, since graphing models and their confidence intervals was practically out<br>
of the question.  Forward and backward regression techniques used linear methods,<br>
requiring less calculation than nonlinear methods, but limited the possible mathematical<br>
models to linear combinations of functions.<br>
<br>
With the advent of computerized calculations, nonlinear methods which were<br>
     impractical in the past could be automated and made practical.  However, the<br>
     nonlinear fitting methods all required starting points for their solvers - meaning in<br>
     practice you had to have a good idea of the final equation parameters to begin with!<br>
<br>
If however a genetic or monte carlo algorithm searched error space for initial parameters<br>
prior to running the nonlinear solvers, this problem could be strongly mitigated.  This<br>
meant that instead of hit-or-miss forward and backward regression, large numbers of<br>
known linear *and* nonlinear equations could be fitted to an experimental data set and<br>
then ranked by a fit statistic such as AIC or SSQ errors.<br>
<br>
This technique is captured in the pyeq3 open source fitting code.  Note that for an initial<br>
guesstimate of parameter values, not all data need be used.  A reduced size data set with<br>
min, max, and (hopefully) evenly spaced additional data points in between are used.  The<br>
total number of data points required is the number of equation parameters plus a few<br>
extra points.<br>
<br>
Reducing the data set size used by the code's genetic algorithm greatly reduces total<br>
processing time.  No secrets here, it's in the open source code.  I tested many different<br>
methods before choosing the one in the code, a genetic algorithm named "Differential Evolution".<br>
<BR>
</td></tr></table>
</div>
