<html><body><table cellpadding="10" border=1>
<tr><th>Fitting History</th><th>Author History</th><th>Links</th></tr>
<tr><td valign="top" width="33%"><br>
Prior to the invention of electronic calculation, only manual methods were available,
of course - meaning that creating mathematical models from experimental data was done
by hand. Even Napier's invention of logarithms did not help much in reducing the
tediousness of this task. Linear regression techniques worked, but how to then
compare models? And so the F-statistic was created for the purpose of model
selection, since graphing models and their confidence intervals was practically
out of the question. Forward and backward regression techniques used linear methods,
requiring less calculation than nonlinear methods, but limited the possible
mathematical models to linear combinations of functions.<br>
<br>
With the advent of computerized calculations, nonlinear methods which were impractical
in the past could be automated and made practical. However, the nonlinear fitting
methods all required starting points for their solvers - meaning in practice you
had to have a good idea of the final equation parameters to begin with!<br>
<br>
If however a genetic or monte carlo algorithm searched error space for initial parameters
prior to running the nonlinear solvers, this problem could be strongly mitigated.  This
meant that instead of hit-or-miss forward and backward regression, large numbers of
known linear *and* nonlinear equations could be fitted to an experimental data set,
and then ranked by a fit statistic such as AIC or SSQ errors.<br>
<br>
Note that for an initial guesstimate of parameter values, not all data need be used.
A reduced size data set with min, max, and (hopefully) evenly spaced additional data
points in between are used.  The total number of data points required is the number
of equation parameters plus a few extra points.<br>
<br>
Reducing the data set size used by the code's genetic algorithm greatly reduces total
processing time.  I tested many different methods before choosing the one in the code,
a genetic algorithm named "Differential Evolution".<br>
<br>
<br>
I hope you find this code useful, and to that end I have sprinkled explanatory comments
throughout the code.  If you have any questions, comments or ridicule, please e-mail
me directly at zunzun@zunzun.com or by posting to the user group at the URL<br>
<a href='https://groups.google.com/forum/#!forum/zunzun_dot_com/'>https://groups.google.com/forum/#!forum/zunzun_dot_com/</a><br>
<br>
I will be glad to help you.<br>
<br>
James R. Phillips<br>
2548 Vera Cruz Drive<br>
Birmingham, AL 35235 USA<br>
<br>
email: zunzun@zunzun.com<br>
</td><td valign="top" width="33%"><br>
This is James Phillips, author of zunzunsite3. My background is in nuclear engineering
and industrial radiation physics, as I started working in the U.S. Navy as a submarine
nuclear reactor operator many, many neutrons ago.<br>
<br>
I have quite a bit of international experience calibrating industrial metal thickness
and coating gauges. For example the thicker a piece of steel the more radiation it
absorbs, and measuring the amount of radiation that passes through a sheet of steel
can tell you how thick it is without touching it. Another example is that the thicker
a zinc coating on steel sheets, the more zinc X-ray fluorescence energy it can
emit - again allowing accurate thickness measurement for industrial manufacture.<br>
<br>
My post-Navy employer originally used ad-hoc spreadsheets to very tediously create
4th-order polynomials calibrating to readings from known samples. So I started
writing my own curve-fitting software in C.<br>
<br>
When X-rays pass through aluminium, the atomic number of the alloying elements
is much greater than that of the aluminium itself such that small changes in alloy
composition lead to large changes in X-ray transmission for the same thickness.
Alloy changes look like thickness changes, egad! However, alloy changes also cause
changes to the X-rays that are scattered back from the aluminium, so that if both
the transmitted and backscattered radiation is measured a more alloy-insensitive
thickness measurement can be made - but this is now a 3D surface fit, and I started
writing surface fitting software. I began to do considerable international work.<br>
<br>
This finally led to the development of my Python fitting libraries, and this code.
I also have wxPython and tkinter desktop versions on GitHub.<br>
<br>
James<br>
</td><td valign="top" width="33%"><br>
Link for animated "Common Problems In Curve Fitting":<br>
<a href='http://commonproblems.readthedocs.io/'>http://commonproblems.readthedocs.io/</a><br>
<br>
Link for Python tkinter desktop version of this computer program:<br>
<a href='https://github.com/zunzun/tkInterFit/'>https://github.com/zunzun/tkInterFit/</a><br>
<br>
Link for this site's source code, which generates PDF files and animated
3D surface rotations:<br>
<a href='https://github.com/zunzun/zunzunsite3/'>https://github.com/zunzun/zunzunsite3/</a><br>
<br>
Link for the pyeq3 fitting library, which has hundreds of known 2D and 3D equations:<br>
<a href='https://github.com/zunzun/pyeq3/'>https://github.com/zunzun/pyeq3/</a><br>
<br>
<br>
</td></tr></table></body></html>
